{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "bb6f01a1c4e2a0dc1db23051045687ea",
     "grade": false,
     "grade_id": "cell-adcd3e653f734bce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "<p>In this project, you will implement a regression tree that predicts the severity of a patient's heart disease based on a set of attributes. The training data is in <code>heart_disease_train.csv</code> and the test data is in <code>heart_disease_test.csv</code>. Before you begin, take a look at the two csv files and  <code>attribute.txt</code>, which contains a description of each attribute in the csv files. You can download the files for review using the links below:</p>\n",
    "\n",
    "* [heart_disease_train.csv](files/heart_disease_train.csv)</li>\n",
    "* [heart_disease_test.csv](files/heart_disease_test.csv)\n",
    "* [attribute.txt](files/attribute.txt)\n",
    "\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong><p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.<p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>\n",
    "<p>You can also download a copy of this notebook in multiple formats using the <strong>Download as</strong> option in the <strong>File</strong> menu above.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "ca2083189cace430509785a83927e68e",
     "grade": false,
     "grade_id": "cell-a388de7633cd305a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "checksum": "65af72493bd06df7e8c8e16812ebca28",
     "grade": false,
     "grade_id": "cell-e9e10d01c7b253bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.6.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/home/codio/workspace/.guides/hf')\n",
    "from helper import *\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "0b1f1ad02980afa11ac5fba46ccee050",
     "grade": false,
     "grade_id": "cell-91646b69c3bc1e6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Implement a Regression Tree</h2>\n",
    "\n",
    "<h3>Part One: Implement <code>load_data</code> [Graded]</h3>\n",
    "\n",
    "Now, implement a function called <code>load_data</code>, which will load the given <code>.csv</code> file and return <code>X, y</code> where <code>X</code> are the patients' attributes and <code>y</code> is the severity of the patients' heart disease. <b>The function should handle two explicit cases. If label=True it should output the training data X and the corresponding label vector y; if label=False it should output only the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39.  1.  3. ...  0.  3.  0.]\n",
      " [47.  1.  3. ...  0.  3.  0.]\n",
      " [41.  1.  2. ...  0.  3.  0.]\n",
      " ...\n",
      " [63.  0.  4. ...  3.  7.  1.]\n",
      " [70.  1.  4. ...  0.  7.  1.]\n",
      " [64.  1.  4. ...  2.  6.  1.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "[[39.  1.  3. ...  1.  0.  3.]\n",
      " [47.  1.  3. ...  1.  0.  3.]\n",
      " [41.  1.  2. ...  1.  0.  3.]\n",
      " ...\n",
      " [63.  0.  4. ...  2.  3.  7.]\n",
      " [70.  1.  4. ...  3.  0.  7.]\n",
      " [64.  1.  4. ...  2.  2.  6.]]\n"
     ]
    }
   ],
   "source": [
    "file='heart_disease_train.csv'\n",
    "data = np.loadtxt(open(file,'rb'),delimiter = ',',skiprows = 1)\n",
    "y = data[:,13]\n",
    "x = data[:,0:13]\n",
    "print(data)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "nbgrader": {
     "checksum": "791e4476e5af06ddcb285545c41e5621",
     "grade": false,
     "grade_id": "cell-load_data",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file='heart_disease_train.csv', label=True):\n",
    "    '''\n",
    "    Input:\n",
    "        file: filename of the dataset\n",
    "        label: a boolean to decide whether to return the labels or not\n",
    "    Returns:\n",
    "        X: patient attributes\n",
    "        y: label (only if label=True)\n",
    "    '''\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    # YOUR CODE HERE\n",
    "    data = np.loadtxt(open(file,'rb'),delimiter = ',',skiprows = 1)\n",
    "    y = data[:,-1]\n",
    "    X = data[:,0:13]\n",
    "    if(label):\n",
    "        return X,y\n",
    "    else:\n",
    "        return X\n",
    "    raise NotImplementedError()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "nbgrader": {
     "checksum": "5fd84258b8c2ff85f9b394e5a59abf8a",
     "grade": false,
     "grade_id": "cell-a4ad4015d5024026",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "nbgrader": {
     "checksum": "3aa1c8dc07572c1c81b4ffdd4a2a36cc",
     "grade": false,
     "grade_id": "cell-load_data_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: load_data_test1 ... ✔ Passed!\n",
      "Running Test: load_data_test2 ... ✔ Passed!\n",
      "Running Test: load_data_test3 ... ✔ Passed!\n",
      "Running Test: load_data_test4 (Testing for correct types) ... ✔ Passed!\n",
      "Running Test: load_data_test5 (Testing training data for correctness) ... ✔ Passed!\n",
      "Running Test: load_data_test6 (training and testing data dimensions should match) ... ✔ Passed!\n",
      "Running Test: load_data_test7 (Testing test data for correctness) ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# The following tests check that your load_data function reads in the correct number of rows, the correct number of unique values for y, and the same training data as the correct implementation\n",
    "\n",
    "Xtrain, ytrain = load_data()\n",
    "Xtrain_grader, ytrain_grader = load_data_grader()\n",
    "Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "Xtest_grader = load_data_grader(file='heart_disease_test.csv', label=False)\n",
    "\n",
    "def load_data_test1():\n",
    "    return (len(Xtrain) == len(ytrain))\n",
    "\n",
    "def load_data_test2():\n",
    "    return (len(Xtrain) == len(Xtrain_grader))\n",
    "\n",
    "def load_data_test3():\n",
    "    y_unique = np.sort(np.unique(ytrain))\n",
    "    y_grader_unique = np.sort(np.unique(ytrain_grader))\n",
    "    \n",
    "    if len(y_unique) != len(y_grader_unique):\n",
    "        return False\n",
    "    else:\n",
    "        return np.linalg.norm(y_unique - y_grader_unique) < 1e-7\n",
    "    \n",
    "def load_data_test4():\n",
    "    return(type(Xtrain)==np.ndarray and type(ytrain)==np.ndarray and type(Xtest)==np.ndarray)\n",
    "\n",
    "def load_data_test5():\n",
    "    Xtrain.sort()\n",
    "    Xtrain_grader.sort()\n",
    "    return np.linalg.norm(Xtrain-Xtrain_grader)<1e-07\n",
    "\n",
    "def load_data_test6():\n",
    "    ntr,dtr=Xtrain.shape\n",
    "    nte,dte=Xtest.shape\n",
    "    return dtr==dte\n",
    "\n",
    "def load_data_test7():\n",
    "    Xtest.sort()\n",
    "    Xtest_grader.sort()\n",
    "    return np.linalg.norm(Xtest-Xtest_grader)<1e-07\n",
    "\n",
    "runtest(load_data_test1,'load_data_test1')\n",
    "runtest(load_data_test2,'load_data_test2')\n",
    "runtest(load_data_test3,'load_data_test3')\n",
    "runtest(load_data_test4,'load_data_test4 (Testing for correct types)')\n",
    "runtest(load_data_test5,'load_data_test5 (Testing training data for correctness)')\n",
    "runtest(load_data_test6,'load_data_test6 (training and testing data dimensions should match)')\n",
    "runtest(load_data_test7,'load_data_test7 (Testing test data for correctness)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "nbgrader": {
     "checksum": "0bbe4dfbb922ab2b853ad39f6127ed2e",
     "grade": true,
     "grade_id": "cell-load_data_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "nbgrader": {
     "checksum": "59fbbb665728e84ec0d01658add23627",
     "grade": true,
     "grade_id": "cell-load_data_test2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "nbgrader": {
     "checksum": "7f19322071b93cfcc6c030e01d4d6e60",
     "grade": true,
     "grade_id": "cell-load_data_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "nbgrader": {
     "checksum": "09e09db395fc07173e7b435d2426aa6a",
     "grade": true,
     "grade_id": "cell-load_data_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "nbgrader": {
     "checksum": "6caa2adc56810d16ee170617a9f389c6",
     "grade": true,
     "grade_id": "cell-load_data_test5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "nbgrader": {
     "checksum": "54ea358256ed0fb875b7574496a18b09",
     "grade": true,
     "grade_id": "cell-load_data_test6",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbgrader": {
     "checksum": "f3928f5e46a1a489737dfdc38403af78",
     "grade": true,
     "grade_id": "cell-load_data_test7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "51b360190ed1942cba7535ea03119142",
     "grade": false,
     "grade_id": "cell-469361b5f1f5f4e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, you will use the regression tree from the previous assignment for this prediction problem. You can implement a regression tree using the function we've provided as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "nbgrader": {
     "checksum": "92dc78070b00a1a8d163d03477e24dcf",
     "grade": false,
     "grade_id": "cell-c90887080a238f11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a regression with no restriction on its depth\n",
    "# if you want to create a tree of depth k\n",
    "# then call RegressionTree(depth=k)\n",
    "tree = RegressionTree(depth=np.inf)\n",
    "\n",
    "# To fit/train the regression tree\n",
    "tree.fit(X, y)\n",
    "\n",
    "# To use the trained regression tree to make predictions\n",
    "pred = tree.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "d7767547d7c18928d479189c0c38a576",
     "grade": false,
     "grade_id": "cell-e422aaa713e45c82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3> Part Two: Find the Optimal Regression Tree [Graded]</h3>\n",
    "\n",
    "In <code>test</code>, you will find the optimal regression tree for the dataset <code>heart_disease_train.csv</code> and return its prediction on <code>heart_disease_test.csv</code>. You will be evaluated based on <code>square_loss</code>. You will get a full score if the test loss on your classifier is less than <strong>0.17</strong>. You may use any functions that you implemented in the previous project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "nbgrader": {
     "checksum": "df2b1c9ba561a745eedc14e91a88e872",
     "grade": false,
     "grade_id": "cell-11c9465dc6096df3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def square_loss(pred, truth):\n",
    "    return np.mean((pred - truth)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(xTr, yTr, xVal, yVal, depths):\n",
    "    '''\n",
    "    Input:\n",
    "        xTr: nxd matrix\n",
    "        yTr: n vector\n",
    "        xVal: mxd matrix\n",
    "        yVal: m vector\n",
    "        depths: a list of len k\n",
    "    Return:\n",
    "        best_depth: the depth that yields that lowest loss on the validation set\n",
    "        training losses: a list of len k. the i-th entry corresponds to the the training loss\n",
    "                the tree of depths[i]\n",
    "        validation_losses: a list of len k. the i-th entry corresponds to the the validation loss\n",
    "                the tree of depths[i]\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    best_depth = None\n",
    "    \n",
    "    lowest_loss = np.inf\n",
    "    for i in depths:\n",
    "        tree = RegressionTree(i)\n",
    "        tree.fit(xTr, yTr)\n",
    "        training_losses.append(square_loss(tree.predict(xTr), yTr))\n",
    "        val_loss = square_loss(tree.predict(xVal), yVal)\n",
    "        validation_losses.append(val_loss)\n",
    "        if val_loss < lowest_loss:\n",
    "            lowest_loss = val_loss\n",
    "            best_depth = i\n",
    "            \n",
    "    return best_depth, training_losses, validation_losses\n",
    "\n",
    "\n",
    "\n",
    "def generate_kFold(n, k):\n",
    "    '''\n",
    "    Input:\n",
    "        n: number of training examples\n",
    "        k: number of folds\n",
    "    Returns:\n",
    "        kfold_indices: a list of len k. Each entry takes the form\n",
    "        (training indices, validation indices)\n",
    "    '''\n",
    "    assert k >= 2\n",
    "    kfold_indices = [None]*k\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    folds = [None]*k\n",
    "    for i in range(k):\n",
    "        start_fold = int((i*n - (i*n)%k)/k)\n",
    "        end_fold = int(((i+1)*n - ((i+1)*n)%k)/k)\n",
    "        a = np.arange(0,start_fold)\n",
    "        b = np.arange(end_fold,n)\n",
    "        training_fold = list(np.append(a,b))\n",
    "        validation_fold = list(np.arange(start_fold,end_fold))\n",
    "        kfold_indices[i] = (training_fold,validation_fold)\n",
    "    return kfold_indices\n",
    "\n",
    "\n",
    "def cross_validation(xTr, yTr, depths, indices):\n",
    "    '''\n",
    "    Input:\n",
    "        xTr: nxd matrix (training data)\n",
    "        yTr: n vector (training data)\n",
    "        depths: a list (of length l) depths to be tried out\n",
    "        indices: indices from generate_kFold\n",
    "    Returns:\n",
    "        best_depth: the best parameter \n",
    "        training losses: a list of lenth l. the i-th entry corresponds to the the average training loss\n",
    "                the tree of depths[i]\n",
    "        validation_losses: a list of length l. the i-th entry corresponds to the the average validation loss\n",
    "                the tree of depths[i] \n",
    "    '''\n",
    "    l = len(depths)\n",
    "    training_losses = [0]*l\n",
    "    validation_losses = [0]*l\n",
    "    best_depth = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in indices:\n",
    "        xTrain = xTr[i[0],:]\n",
    "        yTrain = yTr[i[0]]\n",
    "        xVal = xTr[i[1],:]\n",
    "        yVal = yTr[i[1]]\n",
    "        depth,training_loss,validation_loss = grid_search(xTrain,yTrain,xVal,yVal,depths)\n",
    "        for n in range(l):\n",
    "            training_losses[n] += training_loss[n]\n",
    "            validation_losses[n] += validation_loss[n]\n",
    "    best_depth = depths[np.argmin(validation_losses)]\n",
    "    training_losses[:] = [x / len(indices) for x in training_losses]\n",
    "    validation_losses[:] = [x / len(indices) for x in validation_losses]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return best_depth, training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0.26196911 1.11217949 0.50142857 0.26196911 0.26196911 0.26196911\n",
      " 0.26196911 1.11217949 1.58836996 1.58836996 0.26196911 0.26196911\n",
      " 1.7443634  0.54142857 0.26196911 0.26196911 0.26196911 1.7443634\n",
      " 0.50142857 1.11217949 1.11217949 0.50142857 0.26196911 1.7443634\n",
      " 0.50142857 0.54142857 1.11217949 0.26196911 0.54142857 0.26196911\n",
      " 0.26196911 1.11217949 1.58836996 1.7443634  1.7443634  1.58836996\n",
      " 1.7443634  1.11217949 1.7443634  0.26196911 0.54142857 1.03392857\n",
      " 1.11217949 0.26196911 1.7443634  1.7443634  1.11217949 1.58836996\n",
      " 1.03392857 1.7443634  1.7443634  1.11217949 1.03392857 1.03392857\n",
      " 1.7443634  1.7443634  1.11217949 1.7443634  1.7443634 ]\n"
     ]
    }
   ],
   "source": [
    "depths = [1,2,3,4,5,6,7]\n",
    "Xtrain, ytrain = load_data(file='heart_disease_train.csv', label=True)\n",
    "Xtrain\n",
    "ytrain=ytrain>0\n",
    "Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "indices = generate_kFold(len(Xtrain), 5)\n",
    "best_depth, training_losses, validation_losses = cross_validation(Xtrain, ytrain, depths, indices)\n",
    "print(best_depth)\n",
    "tree2 = RegressionTree(depth=best_depth+1)\n",
    "tree2.fit(Xtrain,ytrain)\n",
    "tree3 = RegressionTree(depth=best_depth-1)\n",
    "tree3.fit(Xtrain,ytrain)\n",
    "prediction2 = tree2.predict(Xtest)\n",
    "prediction3 = tree3.predict(Xtest)\n",
    "print((prediction2+prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "nbgrader": {
     "checksum": "d76034a960e10a697456706e86ab5160",
     "grade": false,
     "grade_id": "cell-test",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    '''\n",
    "        prediction: the prediction of your classifier on the heart_disease_test.csv\n",
    "    '''\n",
    "    prediction = None\n",
    "    Xtrain, ytrain = load_data(file='heart_disease_train.csv', label=True)\n",
    "    ytrain=ytrain>0\n",
    "    Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    depths = [1,2,3,4,5,6,7,8]\n",
    "    indices = generate_kFold(len(Xtrain), 10)\n",
    "    best_depth, training_losses, validation_losses = cross_validation(Xtrain, ytrain, depths, indices)\n",
    "    tree1 = RegressionTree(depth=best_depth)\n",
    "    tree1.fit(Xtrain,ytrain)\n",
    "    tree2 = RegressionTree(depth=best_depth+1)\n",
    "    tree2.fit(Xtrain,ytrain)\n",
    "    tree3 = RegressionTree(depth=best_depth-1)\n",
    "    tree3.fit(Xtrain,ytrain)\n",
    "    prediction = (tree1.predict(Xtest) + tree2.predict(Xtest) + tree3.predict(Xtest))/3\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "nbgrader": {
     "checksum": "57a6eb8a1ae5696ea79fca7414a9e296",
     "grade": false,
     "grade_id": "cell-test_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your test loss: 0.1597\n",
      "Running Test: test_loss_test ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# The following test wil check that your test function returns a loss less than 2 on a sample dataset\n",
    "# ground truth:\n",
    "gt = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "pred = test()\n",
    "test_loss = square_loss(pred, gt)\n",
    "print('Your test loss: {:0.4f}'.format(test_loss))\n",
    "\n",
    "def test_loss_test():\n",
    "    return (test_loss < 0.17)\n",
    "\n",
    "runtest(test_loss_test, 'test_loss_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.248206469010062"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_loss(np.mean(ytrain),gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain=(ytrain>0)*1.0\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "nbgrader": {
     "checksum": "06e7584adfbe6c3c84f7e45446cb4c35",
     "grade": true,
     "grade_id": "cell-test_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test function test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
